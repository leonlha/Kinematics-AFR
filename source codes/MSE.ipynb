{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Define the folder path for cleaned data\n",
    "sorted_folder = r'3_sorted'\n",
    "# \n",
    "merged_folder = r'4_measured'\n",
    "\n",
    "# Image folder\n",
    "original_folder = r'D:\\Research\\GJ DL\\images'\n",
    "\n",
    "# Function to compute MSE between two frames\n",
    "def compute_mse(frame1, frame2):\n",
    "    gray_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    diff = (gray_frame1.astype(np.float32) - gray_frame2.astype(np.float32)) ** 2\n",
    "    mse = np.mean(diff)\n",
    "    return mse\n",
    "\n",
    "# Function to extract frame number from filename\n",
    "def extract_frame_number(filename):\n",
    "    parts = filename.split('Frame')\n",
    "    if len(parts) > 1:\n",
    "        frame_number = parts[1].split('.')[0]\n",
    "        return int(frame_number)\n",
    "    return None\n",
    "\n",
    "def process_and_write(name_file):\n",
    "    if name_file.endswith('.csv'):\n",
    "        # Initialize results list\n",
    "        results = []    \n",
    "\n",
    "        # Read CSV file\n",
    "        print(name_file)\n",
    "        df = pd.read_csv(os.path.join(sorted_folder,name_file))\n",
    "\n",
    "        # Loop through each row in the DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            filename = row['FileName']\n",
    "\n",
    "            # Extract folder name (portion before 'Frame')\n",
    "            folder_name = filename.split('Frame')[0].strip('\\\\')  # Extract folder name\n",
    "            \n",
    "            # Construct image paths using filename\n",
    "            path1 = os.path.join(original_folder, folder_name, filename)\n",
    "            \n",
    "            # For the first row, use the same frame for both previous and current\n",
    "            if index == 0:\n",
    "                path2 = path1\n",
    "            else:\n",
    "                # Get the filename of the previous row\n",
    "                prev_filename = df.loc[index - 1, 'FileName']\n",
    "                path2 = os.path.join(original_folder, folder_name, prev_filename)\n",
    "\n",
    "            # Read frames\n",
    "            # print('path1=',path1)\n",
    "            # print('path2=',path2)\n",
    "            frame1 = cv2.imread(path1)\n",
    "            frame2 = cv2.imread(path2)\n",
    "\n",
    "            # Compute MSE\n",
    "            mse_value = compute_mse(frame1, frame2)\n",
    "\n",
    "            # Append result to list\n",
    "            results.append({\n",
    "                'frame_number': extract_frame_number(filename),\n",
    "                'Distance': mse_value\n",
    "            })\n",
    "\n",
    "        # Create DataFrame from results\n",
    "        results_df = pd.DataFrame(results)\n",
    "\n",
    "        os.makedirs(merged_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "        # Define the output file path + .csv\n",
    "        merged_path = os.path.join(merged_folder, f'4_measured_{folder_name}.csv')\n",
    "        \n",
    "        # Write the result DataFrame to the output CSV file\n",
    "        results_df.to_csv(merged_path, index=False)        \n",
    "\n",
    "# List all files in the folder\n",
    "name_files = os.listdir(sorted_folder)\n",
    "\n",
    "# Specify the number of parallel processes\n",
    "num_cores = -1  # Use all available CPU cores\n",
    "\n",
    "# Execute the tasks in parallel\n",
    "Parallel(n_jobs=num_cores)(\n",
    "    delayed(process_and_write)(name_file)\n",
    "    for name_file in name_files\n",
    "    )\n",
    "# for file_name in file_names:\n",
    "#     (process_and_write)(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "\n",
    "# Define the folder path for cleaned data\n",
    "measured_folder = r'4_measured'\n",
    "threshold_folder = r'5_threshold'\n",
    "\n",
    "# Define percentage of samples\n",
    "number_of_tool = 1\n",
    "percent_sample = 0.5/number_of_tool\n",
    "print(percent_sample)\n",
    "\n",
    "def process_and_write(file_name):\n",
    "    if file_name.endswith('.csv'):\n",
    "\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(os.path.join(measured_folder,file_name))\n",
    "\n",
    "        # Assuming 'Distance' column contains the distances\n",
    "        distances = df['Distance']\n",
    "\n",
    "        print('filename:',file_name,' number of samples:', len(distances))\n",
    "\n",
    "        # Specify the desired number of indices\n",
    "        desired_indices = math.ceil(percent_sample * len(distances))\n",
    "\n",
    "        # Filter rows where distance > 0\n",
    "        filtered_df = df[df['Distance'] > 0]\n",
    "\n",
    "        # Count the number of rows where distance > 0\n",
    "        count_greater_than_zero = filtered_df.shape[0]\n",
    "\n",
    "        print(count_greater_than_zero < desired_indices)\n",
    "\n",
    "        if count_greater_than_zero < desired_indices:\n",
    "            # Initialize a list to store rows (converted to tuples)\n",
    "            indices_where_condition_met = []\n",
    "\n",
    "            # Iterate over rows in filtered_df and append each row to indices_where_condition_met\n",
    "            for index, row in filtered_df.iterrows():\n",
    "                indices_where_condition_met.append(index)\n",
    "        else:\n",
    "            # Initialize threshold value\n",
    "            threshold_value = 0.00001#1  # \n",
    "\n",
    "            # Initialize variables\n",
    "            indices_where_condition_met = []  # List to store indices where condition is met\n",
    "            index = 0\n",
    "\n",
    "            # Iterate until the desired number of indices is reached\n",
    "            while len(indices_where_condition_met) < desired_indices:\n",
    "                # Reset variables\n",
    "                indices_where_condition_met = []\n",
    "                index = 0\n",
    "                \n",
    "                # Loop until all indices are read\n",
    "                while index < len(distances):\n",
    "                    # Initialize current sum for the current set of intervals\n",
    "                    current_sum = 0  + 1e-6\n",
    "                    \n",
    "                    # Loop over intervals starting from the current index\n",
    "                    for i in range(index, len(distances)):\n",
    "                        # Add the distance to the current sum\n",
    "                        current_sum += distances[i]  # Adding 1e-6 to each distance\n",
    "                        \n",
    "                        # Check if the inverse of the sum exceeds the threshold\n",
    "                        if (1 / current_sum) <= threshold_value:\n",
    "                            # Add the index where the condition is met to the list\n",
    "                            indices_where_condition_met.append(i) \n",
    "                            \n",
    "                            # Move to the next index after this interval\n",
    "                            index = i + 1\n",
    "                            break\n",
    "                    else:\n",
    "                        # If no break occurred, all distances were considered and index should be set to the length of distances\n",
    "                        index = len(distances)\n",
    "                    \n",
    "                    # print((1 / current_sum))\n",
    "                    # print('len',len(indices_where_condition_met))\n",
    "                print('number of indices:',len(indices_where_condition_met), '/ desired len:',desired_indices)\n",
    "                # Adjust the threshold value for the next iteration\n",
    "                threshold_value += 0.000001  # Increase the threshold by a small amount\n",
    "\n",
    "            print(\"Threshold value:\", threshold_value)\n",
    "            print(\"Number of indices meeting the condition:\", len(indices_where_condition_met))\n",
    "\n",
    "        # Extract the identifier from the filename \n",
    "        video_id = os.path.splitext(file_name)[0].split('_')[-1]\n",
    "\n",
    "        os.makedirs(threshold_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "        # Define the output file path + .csv\n",
    "        threshold_path = os.path.join(threshold_folder, f'5_threshold_{video_id}.csv')\n",
    "\n",
    "        # Save lines corresponding to the indices where the condition is met\n",
    "        with open(threshold_path, \"w\") as output_file:\n",
    "            # Write the header line\n",
    "            output_file.write('frame_number\\n')\n",
    "            \n",
    "            # Write the indices to the file\n",
    "            for idx in indices_where_condition_met:\n",
    "                # Write the index to the output file\n",
    "                output_file.write(str(df['frame_number'].iloc[idx]) + '\\n')\n",
    "    \n",
    "    # return  threshold_value           \n",
    "\n",
    "# List all files in the folder\n",
    "file_names = os.listdir(measured_folder)\n",
    "\n",
    "# Specify the number of parallel processes\n",
    "num_cores = -1  # Use all available CPU cores\n",
    "\n",
    "# Execute the tasks in parallel\n",
    "Parallel(n_jobs=num_cores)(\n",
    "    delayed(process_and_write)(file_name)\n",
    "    for file_name in file_names\n",
    "    )\n",
    "# for file_name in file_names:\n",
    "#     (process_and_write)(file_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing csv files: 100%|██████████| 30/30 [00:01<00:00, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame based on matching frame numbers has been written to '6_filtered' in text format with custom formatting.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the folder path for cleaned data\n",
    "sorted_folder = r'3_sorted'\n",
    "threshold_folder = r'5_threshold'\n",
    "filtered_folder = r'6_filtered'\n",
    "\n",
    "# Function to extract frame number from filename\n",
    "def extract_frame_number(filename):\n",
    "    parts = filename.split('Frame')\n",
    "    if len(parts) > 1:\n",
    "        frame_number = parts[1].split('.')[0]\n",
    "        return int(frame_number)\n",
    "    return None\n",
    "\n",
    "# List all files in the folder\n",
    "file_names = os.listdir(sorted_folder)\n",
    "\n",
    "# print(file_names)\n",
    "for file_name in tqdm(file_names, desc='Processing csv files'):\n",
    "    if file_name.endswith('.csv'):\n",
    "\n",
    "        # Read the first CSV file into DataFrame\n",
    "        first_file = os.path.join(sorted_folder,file_name)\n",
    "        df_first = pd.read_csv(first_file)\n",
    "\n",
    "        # Extract frame numbers from the 'FileName' column in df_first\n",
    "        df_first['frame_number'] = df_first['FileName'].apply(lambda x: extract_frame_number(x))\n",
    "\n",
    "        # Extract the identifier from the filename \n",
    "        video_id = os.path.splitext(file_name)[0].split('_')[-1]\n",
    "        \n",
    "        # Read the frame numbers from the second CSV file into a list\n",
    "        second_file = os.path.join(threshold_folder, f'5_threshold_{video_id}.csv')\n",
    "        df_second = pd.read_csv(second_file)\n",
    "\n",
    "        # Convert the 'frame_number' column in df_second to a list\n",
    "        frame_numbers_to_keep = df_second['frame_number'].tolist()\n",
    "\n",
    "        # Filter df_first to retain rows with frame numbers that match the ones in the list\n",
    "        df_filtered = df_first[df_first['frame_number'].isin(frame_numbers_to_keep)]\n",
    "\n",
    "        # Keep only unique filenames in the filtered DataFrame\n",
    "        df_filtered = df_filtered.drop_duplicates(subset='FileName')\n",
    "\n",
    "        # Drop the 'frame_number' column from df_filtered\n",
    "        df_filtered.drop('frame_number', axis=1, inplace=True)\n",
    "\n",
    "        os.makedirs(filtered_folder, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "        # Define the output file path + .csv\n",
    "        filtered_path = os.path.join(filtered_folder, f'6_filtered_{video_id}.csv')\n",
    "\n",
    "        # Write the filtered DataFrame to a new text file with custom formatting\n",
    "        with open(filtered_path, 'w') as f:\n",
    "            # Write the DataFrame to the text file row by row with custom formatting\n",
    "            for _, row in df_filtered.iterrows():\n",
    "                # Convert row values to a list of strings\n",
    "                row_values = [str(value) for value in row.tolist()]\n",
    "                # Join row values with '---' and write to file\n",
    "                f.write('---'.join(row_values) + '\\n')\n",
    "\n",
    "print(f\"Filtered DataFrame based on matching frame numbers has been written to '{filtered_folder}' in text format with custom formatting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled lines from CSV files written to: MSE_0_5_v1.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define the folder path containing CSV files\n",
    "folder_path = r'6_filtered'\n",
    "\n",
    "# Define the output file path for the shuffled lines\n",
    "output_file_path = r'MSE_0_5_v1.txt'\n",
    "\n",
    "# Initialize an empty list to store all lines from CSV files\n",
    "all_lines = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    # Check if the file is a CSV file\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        # Read all lines from the CSV file\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        \n",
    "        # Append all lines to the list of all lines\n",
    "        all_lines.extend(lines)\n",
    "\n",
    "# Shuffle all lines randomly\n",
    "random.shuffle(all_lines)\n",
    "\n",
    "# Write the shuffled lines to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.writelines(all_lines)\n",
    "\n",
    "print(f\"Shuffled lines from CSV files written to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts:\n",
      "Class 0: 77 samples\n",
      "Class 1: 38 samples\n",
      "Class 2: 148 samples\n",
      "Class 3: 135 samples\n",
      "Class 4: 225 samples\n",
      "Class 5: 169 samples\n",
      "Class 6: 110 samples\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the text file\n",
    "# file_path = 'train_baseline.txt'\n",
    "file_path = 'MSE_0_01_v1.txt'\n",
    "# file_path = 'train.txt'\n",
    "# file_path = 'train_baseline_0_3_v2.txt'\n",
    "\n",
    "# Dictionary to count occurrences of each class\n",
    "class_counts = {}\n",
    "\n",
    "# Read the file and analyze each line\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split each line by '---'\n",
    "        parts = line.strip().split('---')\n",
    "        \n",
    "        if len(parts) >= 2:\n",
    "            # Extract the class number (the second part after splitting)\n",
    "            class_number = parts[1].strip()\n",
    "            \n",
    "            # Update the class count in the dictionary\n",
    "            if class_number in class_counts:\n",
    "                class_counts[class_number] += 1\n",
    "            else:\n",
    "                class_counts[class_number] = 1\n",
    "\n",
    "# Print the class counts\n",
    "print(\"Class Counts:\")\n",
    "for class_num, count in sorted(class_counts.items()):\n",
    "    print(f\"Class {class_num}: {count} samples\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_ana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
